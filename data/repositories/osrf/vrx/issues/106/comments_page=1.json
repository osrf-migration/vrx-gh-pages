{"pagelen": 100, "values": [{"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/52620726.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-52620726"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": "**Description**\n\nThe purpose of ariac-docker is to perform automated evaluation for the ARIAC competition. This involves two docker images:\n\n1. ARIAC server that runs the simulation and exposes a limited ROS interface \\(only expose ARIAC competition relevant parts\\)\n2. ARIAC competitor base that has ARIAC, but not Gazebo. Teams build off of this image.\n\nBased on [https://bitbucket.org/osrf/ariac/wiki/2019/automated\\_evaluation](https://bitbucket.org/osrf/ariac/wiki/2019/automated_evaluation), this requires that teams provide a folder called `<team_name>` with\n\n* `team_config.yaml`: Their team's sensor configuration file. One sensor configuration is used for all trials.\n* `build_team_system.bash`: A bash script that, when invoked from the command-line on a clean Ubuntu system, will install the necessary dependencies and build the team's code.\n* `run_team_system.bash`: A bash script that, when invoked from the command-line on a system that has had `build_team_system.bash` run, will start the team's system and begin interacting with the ARIAC competition trial.\n\nBased on [https://github.com/osrf/ariac-docker/blob/master/README\\_DEVELOPER.md](https://github.com/osrf/ariac-docker/blob/master/README_DEVELOPER.md), the next step is to run a number of bash scripts to:\n\n1. Pull the latest docker images\n2. Prepare the team systems\n3. Run trials for all teams \\(and log results\\)\n4. Generate videos for all teams\n\n**Proposal**\n\nI propose creating a new repository called `vrx-docker`, similar in structure to `ariac-docker`. The `ariac-docker` repository is quite large and complicated. This could be remedied by clearer organization with more directories. However, I believe that a clearer line between the simulator and the competition containerization is appropriate for a number of reasons:\n\n* Competition containerization and simulation are quite independent modules. In my opinion, separating them makes sense because it will keep commits/history/progress more clear, README\u2019s both easy to see and separate \\(one README for VRX simulation, one README for VRX Competition containerization\\) \\(new users may like to open up a repository and see everything they need to know in the README\\)\n* People using VRX for simulation \\(not competition\\) have no interest in our competition containerization code\n* VRX competitors should, for the most part, not need to actually read and understand the competition containerization with much detail, but simply understand the files they need to create, where they must be put, and how to run the competition. Having the containerization code in VRX may be more intimidating and overwhelming rather than helpful, if they try to look at it with much detail.\n* Based on how these bash scripts work, some of the file structure may get complicated \\(where generated files go, where files need to be stored, where scripts need to be called from, etc.\\). If the containerization code is in the same repository, teams will be pulling this from the repository. I see a higher chance that they may move/delete/add files in inappropriate places that could lead to issues in running the competition, which would be very frustrating for teams who simply want to evaluate their work and not worry about these details. If explained correctly, I see teams being able to only go into the competition containerization code to put their `<team_name>` directory in the right folder, follow the README, and get results easily.\n* This will keep the simulation repository much more simple and focused on simulation\n\n**Argument for Same Repository**\n\n* Could be \u201ccleaner\u201d to have only one repository\n* Could still have clear instructions with the Wiki\n* If we put all the competition containerization code in one directory, it will still look quite clean and simple\n* There is already a docker directory \\(but it is not meant for competition, just simulation\\)\n\n![](data/bitbucket.org/repo/BgXLzgM/images/3807109653-ariac-docker.png)\n  \n_Figure 1: The ariac-docker repository is already quite large and complicated._\n\nI would consider adding a `run_trials`, `run_videos`, and `setup` directory to clarify the structure.", "markup": "markdown", "html": "<p><strong>Description</strong></p>\n<p>The purpose of ariac-docker is to perform automated evaluation for the ARIAC competition. This involves two docker images:</p>\n<ol>\n<li>ARIAC server that runs the simulation and exposes a limited ROS interface (only expose ARIAC competition relevant parts)</li>\n<li>ARIAC competitor base that has ARIAC, but not Gazebo. Teams build off of this image.</li>\n</ol>\n<p>Based on <a data-is-external-link=\"true\" href=\"https://bitbucket.org/osrf/ariac/wiki/2019/automated_evaluation\" rel=\"nofollow\">https://bitbucket.org/osrf/ariac/wiki/2019/automated_evaluation</a>, this requires that teams provide a folder called <code>&lt;team_name&gt;</code> with</p>\n<ul>\n<li><code>team_config.yaml</code>: Their team's sensor configuration file. One sensor configuration is used for all trials.</li>\n<li><code>build_team_system.bash</code>: A bash script that, when invoked from the command-line on a clean Ubuntu system, will install the necessary dependencies and build the team's code.</li>\n<li><code>run_team_system.bash</code>: A bash script that, when invoked from the command-line on a system that has had <code>build_team_system.bash</code> run, will start the team's system and begin interacting with the ARIAC competition trial.</li>\n</ul>\n<p>Based on <a data-is-external-link=\"true\" href=\"https://github.com/osrf/ariac-docker/blob/master/README_DEVELOPER.md\" rel=\"nofollow\">https://github.com/osrf/ariac-docker/blob/master/README_DEVELOPER.md</a>, the next step is to run a number of bash scripts to:</p>\n<ol>\n<li>Pull the latest docker images</li>\n<li>Prepare the team systems</li>\n<li>Run trials for all teams (and log results)</li>\n<li>Generate videos for all teams</li>\n</ol>\n<p><strong>Proposal</strong></p>\n<p>I propose creating a new repository called <code>vrx-docker</code>, similar in structure to <code>ariac-docker</code>. The <code>ariac-docker</code> repository is quite large and complicated. This could be remedied by clearer organization with more directories. However, I believe that a clearer line between the simulator and the competition containerization is appropriate for a number of reasons:</p>\n<ul>\n<li>Competition containerization and simulation are quite independent modules. In my opinion, separating them makes sense because it will keep commits/history/progress more clear, README\u2019s both easy to see and separate (one README for VRX simulation, one README for VRX Competition containerization) (new users may like to open up a repository and see everything they need to know in the README)</li>\n<li>People using VRX for simulation (not competition) have no interest in our competition containerization code</li>\n<li>VRX competitors should, for the most part, not need to actually read and understand the competition containerization with much detail, but simply understand the files they need to create, where they must be put, and how to run the competition. Having the containerization code in VRX may be more intimidating and overwhelming rather than helpful, if they try to look at it with much detail.</li>\n<li>Based on how these bash scripts work, some of the file structure may get complicated (where generated files go, where files need to be stored, where scripts need to be called from, etc.). If the containerization code is in the same repository, teams will be pulling this from the repository. I see a higher chance that they may move/delete/add files in inappropriate places that could lead to issues in running the competition, which would be very frustrating for teams who simply want to evaluate their work and not worry about these details. If explained correctly, I see teams being able to only go into the competition containerization code to put their <code>&lt;team_name&gt;</code> directory in the right folder, follow the README, and get results easily.</li>\n<li>This will keep the simulation repository much more simple and focused on simulation</li>\n</ul>\n<p><strong>Argument for Same Repository</strong></p>\n<ul>\n<li>Could be \u201ccleaner\u201d to have only one repository</li>\n<li>Could still have clear instructions with the Wiki</li>\n<li>If we put all the competition containerization code in one directory, it will still look quite clean and simple</li>\n<li>There is already a docker directory (but it is not meant for competition, just simulation)</li>\n</ul>\n<p><img alt=\"\" src=\"data/bitbucket.org/repo/BgXLzgM/images/3807109653-ariac-docker.png\" /></p>\n<p><em>Figure 1: The ariac-docker repository is already quite large and complicated.</em></p>\n<p>I would consider adding a <code>run_trials</code>, <code>run_videos</code>, and <code>setup</code> directory to clarify the structure.</p>", "type": "rendered"}, "created_on": "2019-06-17T18:55:49.644113+00:00", "user": {"display_name": "Tyler Lum", "uuid": "{305d9368-23ba-4f72-b1d4-7d17d2a062d8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D"}, "html": {"href": "https://bitbucket.org/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/5b96b66385af94340e7cabce/b8bb780f-62b7-47f8-9d03-ee65c7d17ad4/128"}}, "nickname": "tylerlum", "type": "user", "account_id": "5b96b66385af94340e7cabce"}, "updated_on": "2019-06-17T19:17:06.888757+00:00", "type": "issue_comment", "id": 52620726}, {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/52620820.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-52620820"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": "**Other Details**\n\n* ARIAC exposes a limited ROS interface with fork of `gazebo_ros_pkgs` that makes those changes on the server simulator. Is this the method of limiting the ROS interface that we want to do?\n* For VRX, will we be creating videos as well? What will the videos be used for? Just debugging?", "markup": "markdown", "html": "<p><strong>Other Details</strong></p>\n<ul>\n<li>ARIAC exposes a limited ROS interface with fork of <code>gazebo_ros_pkgs</code> that makes those changes on the server simulator. Is this the method of limiting the ROS interface that we want to do?</li>\n<li>For VRX, will we be creating videos as well? What will the videos be used for? Just debugging?</li>\n</ul>", "type": "rendered"}, "created_on": "2019-06-17T19:06:27.440600+00:00", "user": {"display_name": "Tyler Lum", "uuid": "{305d9368-23ba-4f72-b1d4-7d17d2a062d8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D"}, "html": {"href": "https://bitbucket.org/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/5b96b66385af94340e7cabce/b8bb780f-62b7-47f8-9d03-ee65c7d17ad4/128"}}, "nickname": "tylerlum", "type": "user", "account_id": "5b96b66385af94340e7cabce"}, "updated_on": null, "type": "issue_comment", "id": 52620820}, {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/52620991.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-52620991"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": "![](data/bitbucket.org/repo/BgXLzgM/images/1350824550-1.jpg)\n\u200c\n\n![](data/bitbucket.org/repo/BgXLzgM/images/3419384715-2.jpg)\n![](data/bitbucket.org/repo/BgXLzgM/images/3344190490-3.jpg)\n![](data/bitbucket.org/repo/BgXLzgM/images/3700343592-4.jpg)\n![](data/bitbucket.org/repo/BgXLzgM/images/1966645922-5.jpg)", "markup": "markdown", "html": "<p><img alt=\"\" src=\"data/bitbucket.org/repo/BgXLzgM/images/1350824550-1.jpg\" />\n\u200c</p>\n<p><img alt=\"\" src=\"data/bitbucket.org/repo/BgXLzgM/images/3419384715-2.jpg\" />\n<img alt=\"\" src=\"data/bitbucket.org/repo/BgXLzgM/images/3344190490-3.jpg\" />\n<img alt=\"\" src=\"data/bitbucket.org/repo/BgXLzgM/images/3700343592-4.jpg\" />\n<img alt=\"\" src=\"data/bitbucket.org/repo/BgXLzgM/images/1966645922-5.jpg\" /></p>", "type": "rendered"}, "created_on": "2019-06-17T19:23:53.436029+00:00", "user": {"display_name": "Tyler Lum", "uuid": "{305d9368-23ba-4f72-b1d4-7d17d2a062d8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D"}, "html": {"href": "https://bitbucket.org/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/5b96b66385af94340e7cabce/b8bb780f-62b7-47f8-9d03-ee65c7d17ad4/128"}}, "nickname": "tylerlum", "type": "user", "account_id": "5b96b66385af94340e7cabce"}, "updated_on": null, "type": "issue_comment", "id": 52620991}, {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/52623501.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-52623501"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": "I\u2019d like to propose one change to the current ARIAC workflow:\n\n* Instead of teams providing a `build_team_system.bash` and `run_team_system.bash`, we could ask each team to build their own Docker image and upload it to Dockerhub or any other registry. Then, they only need to provide the `yaml` files with the sensor and propulsion configuration, and the URL or the name to their image in the Docker registry where their image is stored.\n\nI know that the original ARIAC solution worked in the past but it\u2019s a source of issues trying to build and run the team\u2019s code. Another issue is that is hard to freeze their code repository, as even after the deadline a team can still work on the code. \n\nThe videos are useful as feedback for the teams, as a tool for challenging a score and also as a way to publish highlights of the competition.", "markup": "markdown", "html": "<p>I\u2019d like to propose one change to the current ARIAC workflow:</p>\n<ul>\n<li>Instead of teams providing a <code>build_team_system.bash</code> and <code>run_team_system.bash</code>, we could ask each team to build their own Docker image and upload it to Dockerhub or any other registry. Then, they only need to provide the <code>yaml</code> files with the sensor and propulsion configuration, and the URL or the name to their image in the Docker registry where their image is stored.</li>\n</ul>\n<p>I know that the original ARIAC solution worked in the past but it\u2019s a source of issues trying to build and run the team\u2019s code. Another issue is that is hard to freeze their code repository, as even after the deadline a team can still work on the code. </p>\n<p>The videos are useful as feedback for the teams, as a tool for challenging a score and also as a way to publish highlights of the competition.</p>", "type": "rendered"}, "created_on": "2019-06-18T01:04:37.011555+00:00", "user": {"display_name": "Carlos Ag\u00fcero", "uuid": "{da8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D"}, "html": {"href": "https://bitbucket.org/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/692bf15758111acaddae4da15a47f9e5d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCA-0.png"}}, "nickname": "caguero", "type": "user", "account_id": "557058:4ded1ddf-947e-4154-bbd1-3dba24f1bdbd"}, "updated_on": null, "type": "issue_comment", "id": 52623501}, {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/52623754.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-52623754"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": "That is a really smart change and it makes a lot of sense. Glad that you found a way to help both issues about changing code after the deadline and building/running the code.", "markup": "markdown", "html": "<p>That is a really smart change and it makes a lot of sense. Glad that you found a way to help both issues about changing code after the deadline and building/running the code.</p>", "type": "rendered"}, "created_on": "2019-06-18T01:47:26.122335+00:00", "user": {"display_name": "Tyler Lum", "uuid": "{305d9368-23ba-4f72-b1d4-7d17d2a062d8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D"}, "html": {"href": "https://bitbucket.org/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/5b96b66385af94340e7cabce/b8bb780f-62b7-47f8-9d03-ee65c7d17ad4/128"}}, "nickname": "tylerlum", "type": "user", "account_id": "5b96b66385af94340e7cabce"}, "updated_on": null, "type": "issue_comment", "id": 52623754}, {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/52642471.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-52642471"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": "Hi Carlos, today I have made some slow, steady progress.\n\n\u200c\n\n**High level plan**:\n\n1. Create a `Dockerfile` for making the `vrx_server` image. It should have every dependency needed to start the simulation and log results. \\(later, will make change to use different branch of Gazebo for not exposing simulator topics\\)\n2. Setup network connection such that `vrx_server` image can be published to from another container\n3. Setup an example Docker image for controlling the simulated boat \\(eg. just tell the boat to go straight forwards\\) that teams will need to supply.\n4. Make the Gazebo fork to limit exposed ROS topics\n5. Create scripts to generate videos\n6. Make scripts to do this for all teams \\(connect the scripts together\\)\n\n**Progress**\n\nSo far, I have been able to do 1 \\(though I have some questions to make sure I am on the right track\\). I am a bit stuck on 2 right now, as I do not have a good understanding about how to set things up.\n\nI am still quite new to Docker, so I have some questions I will list below. I will keep working on them and trying to figure them out as much as I can myself \\(mostly writing it here for myself\\), but if you can give me some guidance on this, that would be really appreciated.\n\n**Questions for 1**\n\n1. In the `Dockerfile` for the `vrx_server` image, I based some of the dependencies on the `docker/Dockerfile` in the vrx repository. However, it has numerous dependencies that I believe are only for development, which aren\u2019t needed \\(eg. git, vim, etc.\\) Is there a clean, simple way I can figure out which ones are needed and which aren\u2019t for the purpose of running the simulator on the server side \\(faster than simply removing and seeing if things break\\) [#!/osrf/vrx/src/default/docker/Dockerfile](#!/osrf/vrx/src/default/docker/Dockerfile) \\(some things like joy\\_teleop are obviously not needed, but I feel we might need  ros-$\\{DIST\\}-velodyne-simulator or ros-$\\{DIST\\}-robot-state-publisher\\)\n2. More of a high level question. Could I simply follow the steps of the tutorial _Install on Host_ [#!/osrf/vrx/wiki/tutorials/SystemSetupInstall](#!/osrf/vrx/wiki/tutorials/SystemSetupInstall)? What differences are there between that and the current docker setup? [#!/osrf/vrx/src/default/docker/Dockerfile](#!/osrf/vrx/src/default/docker/Dockerfile)\n3. `docker/keys` contains and old `ros.key` that no longer works. Related to [http://answers.ros.org/question/325039/apt-update-fails-cannot-install-pkgs-key-not-working/](http://answers.ros.org/question/325039/apt-update-fails-cannot-install-pkgs-key-not-working/). Is there a reason why we store the keys, instead of using `wget http://packages.osrfoundation.org/gazebo.key` or `wget http://packages.ros.org/ros.key`\n4. There is some nvidia-docker related setup in the other Dockerfile. Will we need this for running simulations \\(I am guessing yes for better simulation performance\\)\n5. Are we supporting Gazebo 7 or ROS Kinetic, or just Gazebo 9 and ROS Melodic? \n6. I will share these questions and more when I make a PR, but I just wanted to write it out and maybe get a quick answer on some parts if obvious.\n\n**Questions for 2**\n\n1. I understand that we need to set up a network for the containers to communicate. However, I don\u2019t understand some details about what IP Addresses to use, which IP addresses are available, creating subnets, what do do if I get errors like \n\n`Pool overlaps with other one on this address space, `\n\n`Error response from daemon: Invalid address 172.18.0.22: It does not belong to any of this network's subnets. `\n\n`Error response from daemon: user specified IP address is supported only when connecting to networks with user configured subnets.`\n\n**Questions for 3**\n\n* The new plan is to, instead of have teams give us files `build_team_system.bash` and `run_team_system.bash`, they can give us URL to image \\(that already does the part of `build_team_system.bash`\\). But would they still need to supply a  separate `run_team_system.bash` to be run from inside the container, or should their image both build and run the system?", "markup": "markdown", "html": "<p>Hi Carlos, today I have made some slow, steady progress.</p>\n<p>\u200c</p>\n<p><strong>High level plan</strong>:</p>\n<ol>\n<li>Create a <code>Dockerfile</code> for making the <code>vrx_server</code> image. It should have every dependency needed to start the simulation and log results. (later, will make change to use different branch of Gazebo for not exposing simulator topics)</li>\n<li>Setup network connection such that <code>vrx_server</code> image can be published to from another container</li>\n<li>Setup an example Docker image for controlling the simulated boat (eg. just tell the boat to go straight forwards) that teams will need to supply.</li>\n<li>Make the Gazebo fork to limit exposed ROS topics</li>\n<li>Create scripts to generate videos</li>\n<li>Make scripts to do this for all teams (connect the scripts together)</li>\n</ol>\n<p><strong>Progress</strong></p>\n<p>So far, I have been able to do 1 (though I have some questions to make sure I am on the right track). I am a bit stuck on 2 right now, as I do not have a good understanding about how to set things up.</p>\n<p>I am still quite new to Docker, so I have some questions I will list below. I will keep working on them and trying to figure them out as much as I can myself (mostly writing it here for myself), but if you can give me some guidance on this, that would be really appreciated.</p>\n<p><strong>Questions for 1</strong></p>\n<ol>\n<li>In the <code>Dockerfile</code> for the <code>vrx_server</code> image, I based some of the dependencies on the <code>docker/Dockerfile</code> in the vrx repository. However, it has numerous dependencies that I believe are only for development, which aren\u2019t needed (eg. git, vim, etc.) Is there a clean, simple way I can figure out which ones are needed and which aren\u2019t for the purpose of running the simulator on the server side (faster than simply removing and seeing if things break) <a data-is-external-link=\"true\" href=\"#!/osrf/vrx/src/default/docker/Dockerfile\" rel=\"nofollow\">#!/osrf/vrx/src/default/docker/Dockerfile</a> (some things like joy_teleop are obviously not needed, but I feel we might need  ros-${DIST}-velodyne-simulator or ros-${DIST}-robot-state-publisher)</li>\n<li>More of a high level question. Could I simply follow the steps of the tutorial <em>Install on Host</em> <a data-is-external-link=\"true\" href=\"#!/osrf/vrx/wiki/tutorials/SystemSetupInstall\" rel=\"nofollow\">#!/osrf/vrx/wiki/tutorials/SystemSetupInstall</a>? What differences are there between that and the current docker setup? <a data-is-external-link=\"true\" href=\"#!/osrf/vrx/src/default/docker/Dockerfile\" rel=\"nofollow\">#!/osrf/vrx/src/default/docker/Dockerfile</a></li>\n<li><code>docker/keys</code> contains and old <code>ros.key</code> that no longer works. Related to <a data-is-external-link=\"true\" href=\"http://answers.ros.org/question/325039/apt-update-fails-cannot-install-pkgs-key-not-working/\" rel=\"nofollow\">http://answers.ros.org/question/325039/apt-update-fails-cannot-install-pkgs-key-not-working/</a>. Is there a reason why we store the keys, instead of using <code>wget http://packages.osrfoundation.org/gazebo.key</code> or <code>wget http://packages.ros.org/ros.key</code></li>\n<li>There is some nvidia-docker related setup in the other Dockerfile. Will we need this for running simulations (I am guessing yes for better simulation performance)</li>\n<li>Are we supporting Gazebo 7 or ROS Kinetic, or just Gazebo 9 and ROS Melodic? </li>\n<li>I will share these questions and more when I make a PR, but I just wanted to write it out and maybe get a quick answer on some parts if obvious.</li>\n</ol>\n<p><strong>Questions for 2</strong></p>\n<ol>\n<li>I understand that we need to set up a network for the containers to communicate. However, I don\u2019t understand some details about what IP Addresses to use, which IP addresses are available, creating subnets, what do do if I get errors like </li>\n</ol>\n<p><code>Pool overlaps with other one on this address space,</code></p>\n<p><code>Error response from daemon: Invalid address 172.18.0.22: It does not belong to any of this network's subnets.</code></p>\n<p><code>Error response from daemon: user specified IP address is supported only when connecting to networks with user configured subnets.</code></p>\n<p><strong>Questions for 3</strong></p>\n<ul>\n<li>The new plan is to, instead of have teams give us files <code>build_team_system.bash</code> and <code>run_team_system.bash</code>, they can give us URL to image (that already does the part of <code>build_team_system.bash</code>). But would they still need to supply a  separate <code>run_team_system.bash</code> to be run from inside the container, or should their image both build and run the system?</li>\n</ul>", "type": "rendered"}, "created_on": "2019-06-18T23:08:11.257937+00:00", "user": {"display_name": "Tyler Lum", "uuid": "{305d9368-23ba-4f72-b1d4-7d17d2a062d8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D"}, "html": {"href": "https://bitbucket.org/%7B305d9368-23ba-4f72-b1d4-7d17d2a062d8%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/5b96b66385af94340e7cabce/b8bb780f-62b7-47f8-9d03-ee65c7d17ad4/128"}}, "nickname": "tylerlum", "type": "user", "account_id": "5b96b66385af94340e7cabce"}, "updated_on": "2019-06-18T23:33:15.485274+00:00", "type": "issue_comment", "id": 52642471}, {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/52721101.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-52721101"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": "Answers for 1:\n\n 1. I don\u2019t have a command to figure out the minimum list of packages. I\u2019d start with the dependencies that we already use. It\u2019s not a big problem if have a few extra dependencies.\n\n 2. That\u2019s a good starting point. We\u2019ll need to create a set of extra world files given our task parameters based on a YAML file.\n\n 3. The main reason for storing the key is to avoid sporadic issues trying to download the key from a server.\n\n 4. We\u2019ll need the NVidia setup.\n\n 5. For the competition we\u2019re only supporting Gazebo 9 and ROS Melodic. The scope of this task should only be that environment.\n\n Answers for 2:\n\n  1. I\u2019d have to do more research on this topic but the first thing I\u2019d like is the ARIAC repository to see how this was handled there.\n\n  Answers for 3:\n\n  1. Their Dockerfile should have an entry point that runs their system.", "markup": "markdown", "html": "<p>Answers for 1:</p>\n<ol>\n<li>\n<p>I don\u2019t have a command to figure out the minimum list of packages. I\u2019d start with the dependencies that we already use. It\u2019s not a big problem if have a few extra dependencies.</p>\n</li>\n<li>\n<p>That\u2019s a good starting point. We\u2019ll need to create a set of extra world files given our task parameters based on a YAML file.</p>\n</li>\n<li>\n<p>The main reason for storing the key is to avoid sporadic issues trying to download the key from a server.</p>\n</li>\n<li>\n<p>We\u2019ll need the NVidia setup.</p>\n</li>\n<li>\n<p>For the competition we\u2019re only supporting Gazebo 9 and ROS Melodic. The scope of this task should only be that environment.</p>\n</li>\n</ol>\n<p>Answers for 2:</p>\n<ol>\n<li>I\u2019d have to do more research on this topic but the first thing I\u2019d like is the ARIAC repository to see how this was handled there.</li>\n</ol>\n<p>Answers for 3:</p>\n<ol>\n<li>Their Dockerfile should have an entry point that runs their system.</li>\n</ol>", "type": "rendered"}, "created_on": "2019-06-25T05:13:11.076953+00:00", "user": {"display_name": "Carlos Ag\u00fcero", "uuid": "{da8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D"}, "html": {"href": "https://bitbucket.org/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/692bf15758111acaddae4da15a47f9e5d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCA-0.png"}}, "nickname": "caguero", "type": "user", "account_id": "557058:4ded1ddf-947e-4154-bbd1-3dba24f1bdbd"}, "updated_on": null, "type": "issue_comment", "id": 52721101}, {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/52843276.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-52843276"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": null, "markup": "markdown", "html": "", "type": "rendered"}, "created_on": "2019-07-04T02:05:02.607447+00:00", "user": {"display_name": "Carlos Ag\u00fcero", "uuid": "{da8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D"}, "html": {"href": "https://bitbucket.org/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/692bf15758111acaddae4da15a47f9e5d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCA-0.png"}}, "nickname": "caguero", "type": "user", "account_id": "557058:4ded1ddf-947e-4154-bbd1-3dba24f1bdbd"}, "updated_on": null, "type": "issue_comment", "id": 52843276}, {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/53230517.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-53230517"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": "I\u2019ve tested it and it looks great. Good job!", "markup": "markdown", "html": "<p>I\u2019ve tested it and it looks great. Good job!</p>", "type": "rendered"}, "created_on": "2019-07-31T20:58:35.686973+00:00", "user": {"display_name": "Carlos Ag\u00fcero", "uuid": "{da8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D"}, "html": {"href": "https://bitbucket.org/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/692bf15758111acaddae4da15a47f9e5d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCA-0.png"}}, "nickname": "caguero", "type": "user", "account_id": "557058:4ded1ddf-947e-4154-bbd1-3dba24f1bdbd"}, "updated_on": null, "type": "issue_comment", "id": 53230517}, {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106/comments/53230522.json"}, "html": {"href": "#!/osrf/vrx/issues/106#comment-53230522"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/vrx/issues/106.json"}}, "type": "issue", "id": 106, "repository": {"links": {"self": {"href": "data/repositories/osrf/vrx.json"}, "html": {"href": "#!/osrf/vrx"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e278ca38-7edb-4e62-b785-46dff5617d98}ts=2274605"}}, "type": "repository", "name": "vrx", "full_name": "osrf/vrx", "uuid": "{e278ca38-7edb-4e62-b785-46dff5617d98}"}, "title": "VRX automated evaluation"}, "content": {"raw": "Done in #!/osrf/vrx-docker/", "markup": "markdown", "html": "<p>Done in <a href=\"#!/osrf/vrx-docker/\" rel=\"nofollow\" class=\"ap-connect-link\">#!/osrf/vrx-docker/</a></p>", "type": "rendered"}, "created_on": "2019-07-31T20:58:45.612416+00:00", "user": {"display_name": "Carlos Ag\u00fcero", "uuid": "{da8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D"}, "html": {"href": "https://bitbucket.org/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/692bf15758111acaddae4da15a47f9e5d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCA-0.png"}}, "nickname": "caguero", "type": "user", "account_id": "557058:4ded1ddf-947e-4154-bbd1-3dba24f1bdbd"}, "updated_on": null, "type": "issue_comment", "id": 53230522}], "page": 1, "size": 10}